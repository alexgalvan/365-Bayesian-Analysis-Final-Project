---
title: "Final Project"
output:
  html_document: default
  word_document: default
date: "2025-12-07"
author: "Yuexi Dai, Alexander Galvan, Fatima Hashmi, Dyuthi Ganesh Reddy, and Zhuoxuan Li"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidybayes)
library(tidyverse)
library(rstanarm)
library(bayesplot)
library(posterior)
library(loo)
library(bayesrules)
library(dplyr)
library(broom.mixed)
library(rstan)
```

```{r}
# Load Dataset
wine <- read.csv("WineQT.csv", header = TRUE)
set.seed(36501)
```

# 1. Bayesian Estimation

## 1.1 Discrete data (high-quality/low-quality Wines)

```{r}

## Data Preparation (Defining the Discrete Outcome)
# Define 'High Quality' as quality >= 7
# Define Quality >=7 as 1, else 0 (Binary Outcome)
high_quality_wines <- wine %>%
  mutate(Is_High_Quality = ifelse(quality >= 7, 1, 0))

# Sample Statistics
N <- nrow(high_quality_wines)
Y <- sum(high_quality_wines$Is_High_Quality)
cat("Total number of wines(N):", N, "\n")
cat("Number of high-quality wines (Y):", Y, "\n")

```

**Interpretation:**

For the discrete parameter analysis, we focused on estimating θ(theta), the proportion of high-quality wines in the dataset. We transformed the quality variable (originally ranging from 3 to 9) into a binary outcome by defining wines with quality ≥ 7 as "high quality" (coded as 1) and wines below this threshold as "not high quality" (coded as 0).


### 1.1.1 Prior specification
```{r}

# Model: Y ~ Binomial(N, theta), theta ~ Beta(alpha_0, beta_0)
alpha_0 <- 1.0 
beta_0 <- 1.0

# Prior: θ ~ Beta(1, 1) (Uniform Prior)
```

**Explanation:**

We choose the Beta(1, 1) prior, which is a non-informative Uniform prior.
This prior assigns equal probability density to all possible values of the proportion θ (from 0 to 1).
It is the conjugate prior for the Binomial likelihood, guaranteeing a closed-form posterior solution.

### 1.1.2 Theoretical Posterior (Conjugate)
```{r}

# Posterior parameters
alpha_N <- alpha_0 + Y
beta_N <- beta_0 + N - Y

# Theoretical Summary
theoretical_summary <- data.frame(
  Mean = alpha_N / (alpha_N + beta_N), # E[theta | Y]
  SD = sqrt((alpha_N * beta_N) / ((alpha_N + beta_N)^2 * (alpha_N + beta_N + 1))), # SD of Beta dist
  CI_Lower = qbeta(0.025, alpha_N, beta_N),
  CI_Upper = qbeta(0.975, alpha_N, beta_N)
)

print(theoretical_summary)

```

### 1.1.3 MCMC Estimation using stan()
```{r}

stan_quality_model <- "
  data {
    int<lower=0> N;       
    int<lower=0> Y;        
    real<lower=0> alpha_0; 
    real<lower=0> beta_0;  
  }
  parameters {
    real<lower=0, upper=1> theta; 
  }
  model {
    theta ~ beta(alpha_0, beta_0);

    Y ~ binomial(N, theta);
  }
"
  
# Fit model
quality_stan_fit <- stan(
  model_code = stan_quality_model,
  data = list(N = N, Y = Y, alpha_0 = alpha_0, beta_0 = beta_0),
  chains = 4,
  iter = 10000,
  seed = 36501
)

print(quality_stan_fit, pars = "theta")

```

### 1.1.4 MCMC Diagnotics

**Trace Plot**
```{r}
mcmc_trace(quality_stan_fit, pars = "theta")
```


**Density Plot**
```{r}
# Density Plot
mcmc_dens_overlay(quality_stan_fit, pars = "theta")
```

**Autocorrelation plot**
```{r}
mcmc_acf(quality_stan_fit, pars = "theta")

```

**R-hat values**
```{r}
rhat_value_disc <- summary(quality_stan_fit, pars = "theta")$summary[, "Rhat"]
cat("R-hat value:", rhat_value_disc, "\n")
```

**R-hat = 1.00:** Excellent convergence (< 1.01 threshold).

**Effective sample size ratio**
```{r}
neff_ratio(quality_stan_fit, pars = "theta")
```

**The ESS ratio of 0.334** indicates that about one-third of our 40,000 MCMC samples are statistically independent, which is sufficient for reliable posterior inference.


### 1.1.5 Comparison: MCMC vs Theoretical Posterior
```{r}

# Extract posterior samples
theta_samples <- as.numeric(extract(quality_stan_fit)$theta)

# Numerical comparison
comparison_discrete <- data.frame(
  Method = c("Theoretical (Beta)", "MCMC (Stan)"),
  Mean = c(theoretical_summary$Mean, mean(theta_samples)),
  SD = c(theoretical_summary$SD, sd(theta_samples)),
  CI_2.5 = c(theoretical_summary$CI_Lower, as.numeric(quantile(theta_samples, 0.025))),
  CI_97.5 = c(theoretical_summary$CI_Upper, as.numeric(quantile(theta_samples, 0.975)))
)
print(comparison_discrete)

# Graphical comparison
theta_grid <- seq(0.05, 0.25, length.out = 1000) # Adjust range based on data
theoretical_density_disc <- dbeta(theta_grid, alpha_N, beta_N)

posterior_disc_plot <- ggplot() +
  geom_density(data = data.frame(theta = theta_samples), 
               aes(x = theta, fill = "MCMC"), alpha = 0.5) +
  geom_line(data = data.frame(theta = theta_grid, density = theoretical_density_disc),
            aes(x = theta, y = density, color = "Theoretical"), size = 1.2) +
  scale_fill_manual(values = c("MCMC" = "steelblue")) +
  scale_color_manual(values = c("Theoretical" = "black")) +
  labs(title = "Posterior Distribution: MCMC vs Theoretical (High Quality Proportion)",
       x = "θ (Proportion of High Quality Wines)", y = "Density") +
  theme_minimal() +
  theme(legend.title = element_blank())

print(posterior_disc_plot)
```
**Interpretation:** 

The close alignment between MCMC and theoretical results validates our MCMC implementation and confirms the accuracy of the sampling algorithm. This comparison is possible because the Beta-Binomial model has a closed-form conjugate posterior.


## 1.2 Continuous data (alcohol)
```{r}
alcohol_data <- wine$alcohol
summary(alcohol_data)
```

**For continuous data, we chose alcohol (μ) as the parameter that we are interested in.**

### 1.2.1 Prior specification
```{r}
mu_0 <- 10
sigma_0 <- 2
n <- length(alcohol_data)
y_bar <- mean(alcohol_data)
sigma_known <- sd(alcohol_data)

```

**Prior:** μ ~ N(10, 2²)

**Explanation:**
- μ₀ = 10: typical wine alcohol content is around 10%.
- σ₀ = 2: weakly informative, allowing 95% prior probability.
- Based on general wine knowledge but allows data to dominate.

**Assumed:** σ = 1.082 (known, using sample SD)

### 1.2.2 Theoretical posterior (conjugate)
```{r}

tau_0 <- 1/sigma_0^2
tau <- 1/sigma_known^2
mu_n <- (tau_0*mu_0 + n*tau*y_bar) / (tau_0 + n*tau)
sigma_n <- sqrt(1/(tau_0 + n*tau))

data.frame(
  Mean = mu_n,
  SD = sigma_n,
  CI_Lower = qnorm(0.025, mu_n, sigma_n),
  CI_Upper = qnorm(0.975, mu_n, sigma_n)
)
```

### 1.2.3 MCMC Estimation using stan()
```{r}

stan_model <- "
  data {
    int<lower=0> n;
    vector[n] Y;
    real mu_0;
    real<lower=0> sigma_0;
    real<lower=0> sigma;
  }
  parameters {
    real mu;
  }
  model {
    Y ~ normal(mu, sigma);
    mu ~ normal(mu_0, sigma_0);
  }
"
# Fit model
stan_fit <- stan(
  model_code = stan_model,
  data = list(n = n, Y = alcohol_data, 
              mu_0 = mu_0, sigma_0 = sigma_0, 
              sigma = sigma_known),
  chains = 4,
  iter = 10000,
  seed = 36501
)

print(stan_fit, pars = "mu")

```

### 1.2.4 MCMC Dioagnostics

**Trace Plot**
```{r}
mcmc_trace(stan_fit, pars = "mu")
```

**Interpretation:** Chains mix well with no trends, indicating convergence.

**Density Plot**
```{r}
mcmc_dens_overlay(stan_fit, pars = "mu")
```

**Interpretation:** All chains have similar distributions, confirming convergence.

**Autocorrelation plot**
```{r}
mcmc_acf(stan_fit, pars = "mu")
```

**R-hat values**
```{r}
summary(stan_fit, pars = "mu")$summary[, "Rhat"]
```

**R-hat = 1.00:** Excellent convergence (< 1.01 threshold).

**Effective sample size ratio**
```{r}
neff_ratio(stan_fit, pars = "mu")
```

**An ESS ratio of 0.354** demonstrates highly efficient MCMC sampling with adequate independent samples for the continuous parameter μ.

### 1.2.5 Comparison: MCMC vs Theoretical Posterior

```{r}
# Extract posterior samples
posterior_samples <- as.numeric(extract(stan_fit)$mu)


# Numerical comparison
comparison <- data.frame(
  Method = c("Theoretical", "MCMC (Stan)"),
  Mean = c(mu_n, mean(posterior_samples)),
  SD = c(sigma_n, sd(posterior_samples)),
  CI_2.5 = c(qnorm(0.025, mu_n, sigma_n), 
             as.numeric(quantile(posterior_samples, 0.025))),
  CI_97.5 = c(qnorm(0.975, mu_n, sigma_n), 
              as.numeric(quantile(posterior_samples, 0.975)))
)

print(comparison)
# Graphical comparison
mu_grid <- seq(10.3, 10.6, length.out = 1000)
theoretical <- dnorm(mu_grid, mu_n, sigma_n)

ggplot() +
  geom_density(data = data.frame(mu = posterior_samples), 
               aes(x = mu, fill = "MCMC"), alpha = 0.5) +
  geom_line(data = data.frame(mu = mu_grid, density = theoretical),
            aes(x = mu, y = density, color = "Theoretical"), size = 1.2) +
  scale_fill_manual(values = c("MCMC" = "steelblue")) +
  scale_color_manual(values = c("Theoretical" = "black")) +
  labs(title = "Posterior: MCMC vs Theoretical",
       x = "μ (mean alcohol %)", y = "Density") +
  theme_minimal()

```

**Interpretation:**

The close alignment between MCMC and theoretical posterior validates our MCMC estimation and confirms the accuracy of the sampling algorithm. This comparison is possible because the Normal-Normal conjugate model has a closed-form posterior solution.


# 2. Bayesian Regression

## 2.1 Checking Priors
```{r}
#Full model
summary(wine) #Prior for intercept, quality centered at roughly 5.5 with 1.5 SE

prior_full_wine_model <- stan_glm(
  quality~., data = wine, family = gaussian, 
  prior_intercept = normal(5.5, 1.5), 
  prior = normal(0,  2.5, autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE), 
  chains = 4, iter = 2*5000, seed = 36501, prior_PD = TRUE) 
#Use weakly informative priors for the Coefficients and Sigma

#model relationship defined as
#
#     data:     Y_i | B0, B1,... B12, sigma ~ N(mu_i, sigma^2) with mu_i = B0 + B1*Xi_1 + ... + B12*Xi_12
#     priors:   B0_c ~ N(5.5, 1.5^2)
#               B1,...B12 ~ N(0, 2.5^2) #unassuming location and variance, weak
#               sigma ~ Exp(1)

## Density of the response 
#Plot to show predicted draws from the prior model for quality
wine |>
  add_predicted_draws(prior_full_wine_model, n = 100) |>
  ggplot(aes(x = .prediction, group = .draw)) +
    geom_density() + 
    xlab("quality")

## Plot to show fitted draws from the prior model between quality and alcohol


wine %>% add_fitted_draws(prior_full_wine_model, n=100) %>%
  ggplot(aes(x= alcohol, y=.value)) + geom_line(aes(group=.draw))

## Plot to show fitted draws from the prior model between quality and volatile.acidity
wine %>% add_fitted_draws(prior_full_wine_model, n=100) %>%
  ggplot(aes(x= volatile.acidity , y=.value)) + geom_line(aes(group=.draw))

```
Both plots exhibit weak prior assumptions for coefficients and sigma.

## 2.2 update model to posterior
```{r}
full_wine_model <- update(prior_full_wine_model, prior_PD = FALSE)

# Confirm prior specification, possibly unnecessasry
prior_summary(full_wine_model)

summary(full_wine_model, probs = c(0.025, 0.975))

```


**Interpretation:**

Diagnostics exhibit quick, well-mixing, trace plots with normal densities and low autocorrelation for the features. Rhats show variance stability between and within chains, and effective ratios between 0.4 and 1.1 for our coefficients, sigma, and intercept, also point to low autocorrelation. These diagnostics point to trustworthy results from the MCMC.

Estimates from the posterior summary also show that, for 95% of the probability densities, only volatile.acidity, chlorides, sulphates, and alcohol intervals outside of 0. We'll examine these in a reduced regression model using MCMC.

```{r}

# reduced model
reduced_wine_model <- stan_glm(
  quality~volatile.acidity+chlorides+sulphates+alcohol, 
  data = wine, family = gaussian, 
  prior_intercept = normal(5.5, 1.5), 
  prior = normal(0,  2.5, autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE), 
  chains = 4, iter = 2*5000, seed = 36501) #Same weakly informative priors for the Coefficients and Sigma

summary(reduced_wine_model, probs = c(0.025, 0.975))

```


```{r}
# effective sample size ratio
neff_ratio(reduced_wine_model)
```


### 2.2.1 Check MCMC diagnostics
```{r}
mcmc_trace(reduced_wine_model)
mcmc_dens_overlay(reduced_wine_model)
mcmc_acf(reduced_wine_model)
```

### 2.2.2 Posterior Parameter sampling and comparison to data
```{r}
pp_check(full_wine_model)

pp_check(reduced_wine_model) #Reduced model closer to data observations; multimodel traits of data is due to discrete values for quality.
```

### 2.2.3 Predictions

```{r}

full_predictions <- posterior_predict(full_wine_model, newdata = wine)

reduced_predictions <- posterior_predict(reduced_wine_model, newdata = wine)

ppc_intervals(y = wine$quality, yrep = full_predictions, x = wine$volatile.acidity, prob = 0.5, prob_outer = 0.95) + labs(x = 'Volatile.acidity' , y = 'Quality', title = 'Full Model')

ppc_intervals(y = wine$quality, yrep = reduced_predictions, x = wine$volatile.acidity, prob = 0.5, prob_outer = 0.95) + labs(x = 'Volatile.acidity' , y = 'Quality', title = 'Reduced Model')

```

Reduced model has just as good coverage as full for posterior predictive intervals.

### 2.2.4 Cross validation
```{r}
full_wine_cv <- prediction_summary_cv(data = wine, model = full_wine_model, k = 10)
full_wine_cv$cv

reduced_wine_cv <- prediction_summary_cv(data = wine, model = reduced_wine_model, k = 10)
reduced_wine_cv$cv
```

The MAE between predicted quality and actual is typically small at about 0.4 for both models, 0.62 for scaled errors in both, and 0.53 for 50% PPIs, and 0.94 for 95% PPIs for both models as well. Prediction coverage is good with small error.

```{r}
#Expected Log-Predictive Densities for model comparison
loo_1 <- loo(full_wine_model)
loo_2 <- loo(reduced_wine_model)

c(loo_1$estimates[1], loo_2$estimates[1])

loo_compare(loo_1, loo_2)

```

Full model may have 6 units of better predictive power, with the true difference being roughly within 11.8 units or 2 SE of the estimated difference. With this small, and possibly 0, difference in predictive power, the smaller model is better.

### 2.2.5 Predictions at a particular set of predictor values
```{r}

wine_new <- as.data.frame(reduced_wine_model) |>
  mutate(mu = `(Intercept)` + volatile.acidity*0.7 + chlorides*0.076 + sulphates*0.56 + alcohol*9.4, 
         y_new = rnorm(20000, mu, sigma))

wine_actual_obs <- wine |>
  filter(volatile.acidity == 0.7, chlorides == 0.076, sulphates == 0.56, alcohol == 9.4) #Actual quality is 5

wine_new |>
  ggplot(aes(x = y_new)) +
  geom_density() +
  geom_vline(xintercept = mean(wine_new$y_new))

wine_new |>
  summarise(mean = mean(y_new), sd = sd(y_new), error = 5 - mean(y_new), scaled_error = (5 - mean(y_new)) / sd(y_new))

#c
ppc_intervals(wine$quality, yrep = matrix(wine_new$y_new, ncol = 1143), x = wine$volatile.acidity)

#Model Predictions for some fixed predictor values accurately model the response. Average predicted error from the actual is small, as well as the scaled error. 
```
